{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEX7PDddFErH",
        "outputId": "7a2f9ee9-15c6-40df-85ae-afb7692cf33b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.13.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.models import Model\n",
        "import cv2\n",
        "\n",
        "# Load the VGGFace model\n",
        "model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.save(\"model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4Wk_taqh-Kd",
        "outputId": "618c720f-69cf-40ae-9669-fdf09f53d3a0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from keras.applications.vgg16 import preprocess_input  # Import preprocess_input\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.spatial.distance import euclidean\n",
        "# Load the saved VGG16 model\n",
        "model = load_model(\"model.h5\")\n",
        "\n",
        "# Rest of your code...\n",
        "\n",
        "def extract_vggface_features(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB format\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = preprocess_input(img.astype(np.float32))\n",
        "\n",
        "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "    features = model.predict(img)\n",
        "    return features\n",
        "\n",
        "def extract_orb_features(image_path):\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    orb = cv2.ORB_create()\n",
        "    _, descriptors = orb.detectAndCompute(img, None)\n",
        "    return descriptors\n"
      ],
      "metadata": {
        "id": "AHjy-CF4iBfs"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a list to store base image features and labels\n",
        "base_image_features = []\n",
        "base_image_labels = [1,2,3,4]\n",
        "\n",
        "# Assuming you have 4 base images for 4 classes\n",
        "base_image_paths = [\"base1.jpg\", \"base2.jpg\", \"base3.jpg\", \"base4.jpg\"]\n",
        "for path in base_image_paths:\n",
        "    vgg_features = extract_vggface_features(path)\n",
        "    orb_features = extract_orb_features(path)\n",
        "    # Append features and labels to the lists\n",
        "    base_image_features.append((vgg_features, orb_features))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grgOiR9UizCv",
        "outputId": "e0c9838e-9ea6-4c47-d3f9-5fbd44bc4cc7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 365ms/step\n",
            "1/1 [==============================] - 0s 369ms/step\n",
            "1/1 [==============================] - 0s 377ms/step\n",
            "1/1 [==============================] - 0s 363ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features from the test image\n",
        "test_image_path = \"base1.jpg\"\n",
        "test_vgg_features = extract_vggface_features(test_image_path)\n",
        "test_orb_features = extract_orb_features(test_image_path)\n",
        "\n",
        "test_image_features=[]\n",
        "test_image_features.append((test_vgg_features,test_orb_features))\n",
        "# Create a list to store similarity scores between test and base images\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FC1fau4BzUJ",
        "outputId": "8c04f36d-a6d0-41e7-815f-e4271db92584"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 362ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define a function to calculate similarity\n",
        "def calculate_similarity(test_features, base_features):\n",
        "    # Flatten the arrays if they are not already flattened\n",
        "    test_vgg_flat = test_features[0].flatten() if len(test_features[0].shape) > 1 else test_features[0]\n",
        "    test_orb_flat = test_features[1].flatten() if len(test_features[1].shape) > 1 else test_features[1]\n",
        "    base_vgg_flat = base_features[0].flatten() if len(base_features[0].shape) > 1 else base_features[0]\n",
        "    base_orb_flat = base_features[1].flatten() if len(base_features[1].shape) > 1 else base_features[1]\n",
        "\n",
        "    # Combine the flattened arrays with padding or truncation\n",
        "    max_length = max(len(test_vgg_flat), len(test_orb_flat), len(base_vgg_flat), len(base_orb_flat))\n",
        "\n",
        "    test_vgg_flat = np.pad(test_vgg_flat, (0, max_length - len(test_vgg_flat)))\n",
        "    test_orb_flat = np.pad(test_orb_flat, (0, max_length - len(test_orb_flat)))\n",
        "    base_vgg_flat = np.pad(base_vgg_flat, (0, max_length - len(base_vgg_flat)))\n",
        "    base_orb_flat = np.pad(base_orb_flat, (0, max_length - len(base_orb_flat)))\n",
        "\n",
        "    # Calculate Euclidean distance on the combined features\n",
        "    combined_similarity = euclidean(np.concatenate((test_vgg_flat, test_orb_flat)),\n",
        "                                     np.concatenate((base_vgg_flat, base_orb_flat)))\n",
        "\n",
        "    return combined_similarity\n",
        "\n",
        "# ...\n",
        "similarities=[]\n",
        "# Loop through each base image and calculate similarity\n",
        "for i, base_features in enumerate(base_image_features):\n",
        "    similarity_score = calculate_similarity((test_vgg_features, test_orb_features), base_features)\n",
        "    similarities.append((similarity_score, i))\n",
        "\n",
        "# Find the index of the base image with the minimum similarity score\n",
        "if similarities:\n",
        "    closest_base_index = min(similarities, key=lambda x: x[0])[1]\n",
        "    assigned_class_label = base_image_labels[closest_base_index]\n",
        "    print(f\"The assigned class label is: {assigned_class_label}\")\n",
        "else:\n",
        "    print(\"No similarity scores calculated because 'similarities' list is empty.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQgGWo_sKgSA",
        "outputId": "1762223f-538a-40af-8e7f-d5d6b8909d73"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The assigned class label is: 1\n"
          ]
        }
      ]
    }
  ]
}